---
title: "Project2ComplexModels6372NN"
author: "Nicole Norelli"
date: "4/4/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# data set
# Load CSV file:
# bank.full.csv file
bank.full <- read.csv("~/Downloads/bank/bank-full.csv", sep=";", stringsAsFactors=TRUE)
# Because these seem to be sequentially ordered, make a ID number in order
bank.full = bank.full %>%
  mutate(id = row_number())

# Now add in the year variable
bank.full = bank.full %>%
  mutate(year = case_when(id>=1 & id<=27729 ~ '2008',
                          id>=27730 & id<=42591 ~ '2009',
                          id>=42592 ~ '2010'))
bank.full$year = factor(bank.full$year)

# Let's reorder month so it makes sense on graphs
bank.full$month = factor(bank.full$month, levels=c("jan","feb","mar","apr","may","jun","jul","aug","sep","oct","nov","dec"))

# Change pdays -1 to 0:
bank.full$pdays[bank.full$pdays==-1] = 0

# Remove outlier (other in 2008)
bank.full = subset(bank.full, previous != 275)

# Remove 2008
bank.full.new = bank.full %>%
  filter(year != 2008)
# Drop level 2008
bank.full.new$year = droplevels(bank.full.new$year)
```

```{r}
# train test split
# 80/20 would be: 13985:3496
set.seed(1234)
index<-sample(1:dim(bank.full.new)[1],3496,replace=F)
test<-bank.full.new[index,]
train<-bank.full.new[-index,]
```

```{r}
# Build a logistic regression using glm() with all predictors to start
# Code from AutoClassify.R
library(ResourceSelection)
# Using glm
model.main<-glm(y ~ age+job+marital+education+default+balance+housing+loan+contact+day+month+duration+campaign+pdays+previous+poutcome+year, data=train,family = binomial(link="logit"))
(vif(model.main)[,3])^2
#Hosmer Lemeshow test for lack of fit.  Use as needed.  The g=10 is an option that deals with the continuous predictors if any are there.
#This should be increased with caution. 
hoslem.test(model.main$y, fitted(model.main), g=10)
# rejects. But the sample size is large, so I don't think it's an issue
#Summary of current fit
summary(model.main)
# Using the summary coefficients we can generate CI for each one in the table
exp(cbind("Odds ratio" = coef(model.main), confint.default(model.main, level = 0.95)))
# AIC: 10333
```

```{r}
library(ResourceSelection)
#This starts with a null model and then builds up using forward selection up to all the predictors that were specified in main model previously.
# Code from AutoClassify.R
model.null<-glm(y ~ 1, data=train,family = binomial(link="logit"))
step(model.null,
     scope = list(upper=model.main),
     direction="forward",
     test="Chisq",
     data=train)
```

```{r}
# try some interactions
model.complex<-glm(y ~ age+job+marital+education+default+balance+housing+loan+contact+day+month+duration+campaign+pdays+previous+poutcome+year+year:month+year:day+I(duration^2)+I(pdays^2), data=train,family = binomial(link="logit"))
step(model.main,
     scope = list(upper=model.complex),
     direction="forward",
     test="Chisq",
     data=newAuto)
# Success! looks like yearxday and yearxmonth were significant
# AIC: 10010
# Try squaring each of the numerical variables
# Success! duration^2 is significant too
# AIC: 9730
# Success! also pdays^2 is significant
# AIC: 9726
```

```{r}
# change starting model to model.null
model.complex<-glm(y ~ age+job+marital+education+default+balance+housing+loan+contact+day+month+duration+campaign+pdays+previous+poutcome+year+year:month+year:day+I(duration^2)+I(pdays^2), data=train,family = binomial(link="logit"))
step(model.null,
     scope = list(upper=model.complex),
     direction="forward",
     test="Chisq",
     data=newAuto)
# This is better!:
# AIC: 9719
# y ~ month + duration + poutcome + I(duration^2) + year + housing + day + contact + education + campaign + loan + marital + I(pdays^2) + pdays + month:year + year:day
# does not include: age, previous, balance, default, job
model.forward.complex = glm(y ~ month + duration + poutcome + I(duration^2) + year + housing + day + contact + education + campaign + loan + marital + I(pdays^2) + pdays + month:year + year:day, data=train,family = binomial(link="logit"))
(vif(model.forward.complex)[,3])^2
summary(model.forward.complex)
plot(model.forward.complex)
# AIC: 9718
# might need to try alternate route to look at vifs
# what's going on w/ obs 3018?
# looks like it's the highest duration in the training set (3102)
```

```{r}
# Code from HW 12
# Try stepwise selection using AIC as stopping criterion
library(MASS)
library(tidyverse)
full.log.complex<-glm(y ~ age+job+marital+education+default+balance+housing+loan+contact+day+month+duration+campaign+pdays+previous+poutcome+year+year:month+year:day+I(duration^2)+I(pdays^2),family="binomial",data=train)
step.log.complex<-full.log.complex %>% stepAIC(trace=FALSE)
coef(step.log.complex)
summary(step.log.complex)
exp(cbind("Odds ratio" = coef(step.log.complex), confint.default(step.log.complex, level = 0.95)))
vif(step.log.complex)
# model: y ~ marital + education + housing + loan + contact + day + month + duration + campaign + pdays + poutcome + year + I(duration^2) + I(pdays^2) + month:year + day:year
# same as above
# AIC: 9718
```

```{r}
# Try LASSO
# Cross validation is used to obtain the optimal penalty value.  A final refit using the entire data set can then be obtained once the optimal penalty value is determined.  For this example, the object "finalmodel" produces the final lasso model.
library(glmnet)
dat.train.complex.x <- model.matrix(y~age+job+marital+education+default+balance+housing+loan+contact+day+month+duration+campaign+pdays+previous+poutcome+year+year:month+year:day+I(duration^2)+I(pdays^2)-1,train)
dat.train.y<-train$y
cvfit <- cv.glmnet(dat.train.complex.x, dat.train.y, family = "binomial", type.measure = "class", nlambda = 1000)
plot(cvfit)
coef(cvfit, s = "lambda.min")
#CV misclassification error rate is 0.1717555
print("CV Error Rate:")
cvfit$cvm[which(cvfit$lambda==cvfit$lambda.min)]

#Optimal penalty
print("Penalty Value:")
cvfit$lambda.min

#For final model predictions go ahead and refit lasso using entire data set
finalmodel.complex<-glmnet(dat.train.complex.x, dat.train.y, family = "binomial",lambda=cvfit$lambda.min)

# basically all but default
# CV Error Rate: 0.1626743 (lower than w/o complex terms)
```

```{r}
# Make predictions on test set using LASSO model
dat.test.complex.x<-model.matrix(y~age+job+marital+education+default+balance+housing+loan+contact+day+month+duration+campaign+pdays+previous+poutcome+year+year:month+year:day+I(duration^2)+I(pdays^2)-1,test)
dat.test.y<-test$y
fit.pred.lasso.complex <- predict(finalmodel.complex, newx = dat.test.complex.x, type = "response")

#Making predictions for stepwise as well
fit.pred.step.complex<-predict(step.log.complex,newdata=test,type="response")
# error message: prediction from a rank-deficient fit may be misleading???
# NEED TO RESEARCH THAT
# I think maybe there aren't enough cases in some of the cells for the test set or it's the multicollinearity?
```

```{r}
cutoff<-0.5
class.lasso.complex<-factor(ifelse(fit.pred.lasso.complex>cutoff,"yes","no"),levels=c("no","yes"))
class.step.complex<-factor(ifelse(fit.pred.step.complex>cutoff,"yes","no"),levels=c("no","yes"))

#Confusion Matrix for Lasso
conf.lasso.complex<-table(class.lasso.complex,test$y)
print("Confusion matrix for LASSO")
conf.lasso.complex

conf.step.complex<-table(class.step.complex,test$y)
print("Confusion matrix for Stepwise")
conf.step.complex

#Accuracy of LASSO and Stepwise
print("Overall accuracy for LASSO and Stepwise respectively")
sum(diag(conf.lasso.complex))/sum(conf.lasso.complex)
sum(diag(conf.step.complex))/sum(conf.step.complex)

# 0.5 cut-off:
# [1] "Confusion matrix for LASSO"
#                    
# class.lasso.complex   no  yes
#                 no  2509  382
#                 yes  207  398
# [1] "Confusion matrix for Stepwise"
#                   
# class.step.complex   no  yes
#                no  2505  380
#                yes  211  400
# [1] "Overall accuracy for LASSO and Stepwise respectively"
# [1] 0.8315217
# [1] 0.8309497
```

```{r}
library(ROCR)
#ROC curves: LASSO model on test set
pred1.complex <- prediction(fit.pred.lasso.complex[,1], dat.test.y)
roc.perf1.complex = performance(pred1.complex, measure = "tpr", x.measure = "fpr")
auc.val1.complex <- performance(pred1.complex, measure = "auc")
auc.val1.complex <- auc.val1.complex@y.values
plot(roc.perf1.complex, colorize=TRUE)
abline(a=0, b= 1)
text(x = .40, y = .6,paste("AUC = ", round(auc.val1.complex[[1]],3), sep = ""))
# AUC=0.884

# Code from HW 12
#ROC curves: Step model on test set
results.step.complex<-prediction(fit.pred.step.complex, test$y,label.ordering=c("no","yes"))
roc.step.complex = performance(results.step.complex, measure = "tpr", x.measure = "fpr")
auc.val.step.complex = performance(results.step.complex, measure="auc")
auc.val.step.complex = auc.val.step.complex@y.values
plot(roc.step.complex,colorize = TRUE)
abline(a=0, b= 1)
text(x = .40, y = .6,paste("AUC = ", round(auc.val.step.complex[[1]],3), sep = ""))
# AUC=0.887
```
